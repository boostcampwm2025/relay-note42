# Week2
`J009_강성재` `J059_김윤서` `J068_김준서` `S016_서준영`

## Week1 퀘스트

| 퀘스트 번호 | 내용                                                                         |
| ----------- | ---------------------------------------------------------------------------- |
| Quest 1     | 매일 채점 프롬프트를 이용해, 피어세션 문서의 부족한 부분을 AI에게 피드백받기 |
| Quest 2     | 매일 채점 프롬프트를 조금씩 개선하며 더 나은 피드백을 받을 수 있게 만들기    |
| Quest 3     | 피어세션 전에 AI에게 “이 자료에 대해 어떤 질문을 받을 수 있을까?”를 물어보기 |
| Quest 4     | 나의 루틴을 AI에게 공유하고, 정해진 시간마다 알림을 받아 실천 여부 점검하기  |

### Week1 퀘스트 수행 기록

### `J094 노주호`
1. **`선택한 퀘스트`**
    - `Quest 3. AI에게 더 나은 질문 만들기`
2. **`개선할 사항: -`**

### `J260 지은미`
1. **`선택한 퀘스트`**
    - `Quest 1. 피어세션용 문서를 AI로 채점받기`
    - `Quest 3. AI에게 더 나은 질문 만들기`
2. **`개선할 사항: 정리하는 부분에서는 질문의 퀄리티나 정리하는 방식을 조금 더 학습시켜 실험해봐야겠다는 생각을 했다. 아쉬웠던건 지피티 특유의 정리 방식으로 정리를 진행해줘서 내가 정리한 느낌이 안난다는 아쉬움이 있었다. 내가 정리하는 방식에 대해 학습을 시켜놓은 뒤, 정리를 부탁하면 더 만족하는 정리본을 얻을 수 있을 것 같다.`**

### `J017 곽윤철`
1. **`선택한 퀘스트`**
    - `Quest 1. 피어세션용 문서를 AI로 채점받기`
2. **`개선할 사항: -`**

### `S005_김성훈`
1. **`선택한 퀘스트`**
    - `Quest 3. AI에게 더 나은 질문 만들기`
2. **`개선할 사항: "무엇을 알고 싶은지"뿐만 아니라 "왜, 어떤 상황에서" 궁금한지도 함께 담는 것이 중요하다`**

## Week2 퀘스트

| 퀘스트 번호 | 내용                                                               |
| ----------- |------------------------------------------------------------------|
| Quest 1     | 채점 프롬프트를 이용해, 피어세션 문서의 부족한 부분을 AI에게 피드백받고, 피드백 내용을 참고해 보완하고 개선하기 |
| Quest 2     | 칭찬과 피드백 포인트를 미리 기록해 둘 수 있는 피어세션 템플릿 만들기                  |
| Quest 3     | 피어세션 문서와 예상 질문들을 기반으로 보다 예리하고 유의미한 질문 생성해보기                      |
| Quest 4     | 일정과 루틴에 맞춰 알림 보내주는 슬랙 봇 만들어보기                                    |

## 퀘스트 개선 과정

### 토론
`J059_김윤서` `J068_김준서`
- 피어 세션 피드백 경험 공유
    - 1주차는 서먹함/막막함 등으로 표면적 피드백과 의견 공유 수준
    - 2주차는 약간의 익숙해짐과 학습 경험을 통해 비교적 세부적인 피드백 진행,  
      나름의 기준과 방식을 지정해 진행했으나, 심층적 피드백을 통한 유의미한 결과물 산출은 미미
    - 보다 유의미하고 생산적인 피드백 필요성 공감
    - 해당 내용 반영해 퀘스트 보완 및 수정

### Quest 1  
before | after  
|--------|--------|  
| 매일 채점 프롬프트를 이용해, 피어세션 문서의 부족한 부분을 AI에게 피드백받기 | 채점 프롬프트를 이용해, 피어세션 문서의 부족한 부분을 AI에게 피드백받고, 피드백 내용을 참고해 보완하고 개선하기 |  

<br />

#### ✏️ 수정된 이유  
- 기존에는 AI 채점만 받고 끝나는 경우가 많았음  
- 프롬프트 실험은 했지만, 그 결과를 반영한 문서 개선까지 이어지지 않아 아쉬움
- 일부 참가자 피드백처럼, GPT의 일관된 정리 방식이 아쉬웠고  
  → 내가 원하는 정리 스타일을 반영하거나, 직접 수정하는 과정이 필요했음  

<br />

#### 💬 토론 내용  
- 1주차 피어세션 질문은 어색하거나 쥐어짠 느낌이 많았고  
  피드백을 받아도 질문 개선으로 이어지지 않는 경우가 대부분
- 퀘스트 1, 2가 분리되어 있어 루틴이 흐지부지될 수 있다는 피드백
- “그냥 피드백만 받는 게 아니라, 받고 나서 어떻게 바꿨는지까지 정리해야 의미가 있다”는 의견 다수  

<br />

#### 🔍 조사 활동  
- 실제로 다양한 프롬프트 실험 진행  
  - 같은 질문을 더 구체적으로 표현했을 때, AI 피드백이 어떻게 달라지는지 비교  
  - “질문 설계 배경”을 추가하면 더 명확한 개선점이 나오는 것을 확인  
- 일부 참가자는 AI가 주는 정리 스타일이 아쉽다고 응답  
  → GPT에게 내가 원하는 정리 스타일을 먼저 학습시키고 나서 피드백을 요청하는 방식도 시도  

<br /> <br />

### Quest 2  
| before | after |
|--------|-------|
| --- | 칭찬과 피드백 포인트를 미리 기록해 둘 수 있는 피어세션 템플릿 만들기 |

<br />

#### ✏️ 수정된 이유
- 피어세션에서 피드백을 즉흥적으로 주고 끝나는 경우가 많았음  
- 미리 칭찬할 점과 아쉬운 점을 적어두면, 피드백이 더 구체적이고 풍부해질 수 있음  
- 처음부터 정해진 양식은 없었지만, 서로에게 도움이 되는 문서를 만들어보자는 취지로 시작

<br />

#### 💬 토론 내용
- 질문이 어색하다는 피드백이 있었고, 왜 그런 질문을 했는지 보이지 않는다는 의견이 많았음  
- 피어세션 전에 좋았던 점과 피드백 포인트를 미리 생각해두면 더 깊이 있는 대화가 가능하다는 공감대  
- AI 피드백과 사람 피드백을 모두 담을 수 있는 간단하고 명확한 템플릿이 있으면 좋겠다는 결론
  
<br />

#### 🔍 조사 활동
- 기존에 그런 문서는 없었지만, 어떻게 하면 서로 피드백을 잘 주고받을 수 있을까를 중심으로 논의  
- 몇 가지 항목(칭찬할 점, 개선할 점, 질문 의도 등)을 정리해서 템플릿 형태로 만들어보기로 함
- 실제로 작성해보니 피드백이 더 명확하고 전달이 쉬워짐을 느꼈음

### Quest 3
before | after  
|--------|--------|  
| 피어세션 전에 AI에게 “이 자료에 대해 어떤 질문을 받을 수 있을까?”를 물어보기 | 피어세션 문서와 예상 질문들을 기반으로 보다 예리하고 유의미한 질문 생성해보기 |  

<br />

#### ✏️ 수정된 이유
- 예상 질문을 일방적으로 수용만 해선 유의미한 개선점을 파악하고 보완할 수 없음
- 피어 피드백 과정에서 주고받을 질문이 부족하거나, 얕은 질문으로 금방 마무리되는 경우 다수
- 작성한 코드에 대한 심층적 이해 부족을 스스로 개선해나갈 필요성 자각

<br />

#### 💬 토론 내용
- 피어 피드백을 진행할 때 질문이 겉돌거나 유의미한 결과를 내지 못하는 경우가 많음
- 받을 질문을 선제적으로 받아 버리니 자주적인 학습이 차단되는 느낌

<br />

#### 🔍 조사 활동
- 최근 미션(day09) 학습 정리를 기반으로,  
  직접 구상한 질문과 피어 피드백 과정에서 주고받은 질문을 입력,
  - `각각의 문서에 정리된 내용을 기반으로 어떤 질문을 할 수 있을까?`
  - `좀더 개선되거나 핵심적인 내용을 묻는 질문으로 개선할 수 있을까?`
- ### 개선안 : 설계와 반복
    - 기존 질문 / 개선 질문 제안 생성, 질문에 대한 질문을 통해 본질적인 내용을 파악하기
    - 표면적 기능 설명 묻기→"왜 꼭 그 구조인가? 현실에서 부작용·트레이드오프는?" 등으로  
      맥락을 설계와 실무, 성능, 품질에 끊임없이 연결하기
    - 보편적인 컨셉(불변성, 싱글톤, 동기화 등)과 설계 패턴이 **자신의 문제에 정말 맞는가? 충분한가?** 를  
      반복해서 물으며, 대체 구조·한계·사용 맥락을 탐구하는 것이 중요하다

<br /> <br />

### Quest 4
before | after  
|--------|--------|  
| 나의 루틴을 AI에게 공유하고, 정해진 시간마다 알림을 받아 실천 여부 점검하기 | 일정과 루틴에 맞춰 알림 보내주는 슬랙 봇 만들어보기 |  

<br />

#### ✏️ 수정된 이유
- 기존 미션 `나의 루틴을 AI에게 공유하고, 정해진 시간마다 알림을 받아 실천 여부 점검하기`  
  은 대부분의 모델이 알림 전송 기능을 제공하지 않으므로 실천 불가.
- 대부분의 모델은 직접적 알림 전송은 불가하지만 해당 기능을 제공하는 프로그램 생성을 권유.
- 코어 타임 동안 온-라인 해야 하는 슬랙에 봇 추가하는 방식으로 우회.

<br />

#### 💬 토론 내용
- 각자의 일정 진행 방식과 루틴이 존재하고,  
  일정 알림 기능의 필요성은 공감하나 해당 기능을 제공하는 모델은 거의 없음
- 다만 슬랙 봇을 통해 동일 기능을 제공은 가능 like booduki
- 자신만의 슬랙봇 만들어보기 퀘스트로 수정.

<br />

#### 🔍 조사 활동
- 슬랙 봇 제작 방식

| 단계               | 설명                                               |
|:------------------:|:--------------------------------------------------|
| 워크스페이스 준비   | 슬랙 워크스페이스 생성 또는 기존 워크스페이스 참여 |
| 앱/봇 생성         | Slack API에서 앱 및 봇 계정 추가, 권한 세팅        |
| 토큰 발급          | 앱 설치 후 Bot Token(시크릿 키) 발급              |
| 개발 및 테스트      | 봇 코드 작성 및 기능 테스트                       |
| 배포               | 서버·클라우드 등에 배포하여 실서비스로 운영        |

- ### 개선안 : 자신만의 슬랙봇
  - 스스로 슬랙봇을 만들어보는 경험을 넘어, 자신만의 커스터마이징을 통한 
  - 사용자 맞춤형 봇 만들고 활용해 보기

- ## 정리
  - 보다 실천 가능한, 프로젝트의 목표에 부합한 퀘스트로의 개선을 통해
  - 더욱 효과적인, 의미있는 피드백을 진행하고 지속 가능한 성장을 추구하기

<br /> <br />

## 27조의 멤버가 선택한 퀘스트

### `S001 강윤서`
1. **`선택한 퀘스트`**
    - `Quest 2. 칭찬과 피드백 포인트를 미리 기록해 둘 수 있는 피어세션 템플릿 만들기`
    - **`선택한 이유: 피어피드백에 대한 정해진 방법은 없지만 피어 피드백 시간이 항상 부족하다고 느꼈고, 생각나는 대로 주제를 꺼내다 종료되었던 적이 많다. 피어 피드백 템플릿을 만들어두면, 피드백 요소 뿐만아니라 칭찬을 통해 긍정 피드백도 잊지 않고 할 수 있다는 점에서 2번을 선택했다.`**
### `J250 조동협`
1. **`선택한 퀘스트`**
    - `Quest 1. 피어세션용 문서를 AI로 채점받기`
    - **`피어 세션하는 이유는 다른 분의 시각에서의 의견을 통해 내 코드를 점검하는 것이다, 이때 발전된 AI를 효율적인 프롬프트를 통해서 점검 받는다면 더 좋은 피어 세션을 통해 같은 팀원들의 코드 발전이 기대되어 이 퀘스트를 선택하였습니다.`**
### `J033 김동완`
1. **`선택한 퀘스트`**
    - `Quest 1. 피어세션용 문서를 AI로 채점받기`
    - **`선택한 이유: 기존 피어 세션에서는 대부분 긍정적인 피드백에 머물러, 실질적인 개선점이나 '쓴소리'를 듣기 어려웠습니다. AI를 활용해 객관적인 분석으로 명확한 피드백을 받고 싶습니다. 이를 통해 제 문제점을 명확하게 찾고자 합니다.`**
### `J165_유태근`
1. **`선택한 퀘스트`**
    - `Quest 3. 피어세션 문서와 예상 질문들을 기반으로 보다 예리하고 유의미한 질문 생성해보기`
    - **`선택한 이유: 피어 피드백 전에 내 작업물에 대한 예상 질문을 단편적으로 만들어보는 것만으로는, 질문을 수동적으로 수용하는 데 그쳐 작업물에 대한 본질적인 이해나 실질적인 개선으로 이어지기 어려웠습니다. 그래서 단순히 예상 질문을 받아들이는 데서 나아가, 그 질문을 AI에게 다시 질문하며 나의 코드와 설계를 더 깊이 성찰하고자 이 퀘스트를 선택했습니다.`**

---

# 27조 멤버의 퀘스트 후기

**`J250 조동협`**

1. **`선택한 퀘스트`**
    - `Quest 1. 피어세션용 문서를 AI로 채점받기`
    - 채점 프롬프트를 이용해, 피어세션 문서의 부족한 부분을 AI에게 피드백받고, 피드백 내용을 참고해 보완하고 개선하기
- 사용한 프롬프트 (  J017 피어분의 기존 프롬포트가 좋아서 이를 이용했습니다.)
    
    ```
    당신은 냉정하고 객관적인 개발 문서 평가자입니다. 감정이나 격려는 배제하고, 오직 사실과 기준에 근거하여 평가하세요. 제공된 문서가 문제 분석부터 구현까지의 전체 개발 과정을 얼마나 잘 기록하고 있는지 평가해주세요.
    
    **평가 원칙:**
    
    - 절대 관대하게 점수를 주지 마세요
    - 애매한 부분은 낮은 점수로 평가하세요
    - 실제로 확인 가능한 내용만 인정하세요
    - 부족한 부분은 구체적으로 지적하세요
    
    **필수 평가 기준:**
    
    **1. 개발 과정의 완전성 (30%)**
    
    - 문제 분석 → 설계 → 구현의 전체 흐름이 명확히 기술되어 있는가?
    - 각 단계별 의사결정 과정과 근거가 제시되어 있는가?
    - 개발 과정에서의 시행착오나 변경사항이 투명하게 기록되어 있는가?
    
    **2. 과정의 연결성과 맥락 (25%)**
    
    - 각 단계 간의 논리적 연결이 자연스러운가?
    - 이전 단계의 결과가 다음 단계에 어떻게 반영되었는지 명확한가?
    - 전체 개발 스토리가 일관성 있게 전개되는가?
    
    **3. 코드 실행 결과 기록의 충실성 (25%)**
    
    - 주요 코드 실행 결과(출력, 로그, 테스트 결과 등)가 포함되어 있는가?
    - 실행 결과에 대한 해석과 분석이 제공되는가?
    - 예상 결과와 실제 결과의 비교 분석이 있는가?
    - 오류 발생 시 디버깅 과정과 해결 과정이 기록되어 있는가?
    
    **4. 기술적 설명의 품질 (20%)**
    
    - 코드와 알고리즘에 대한 이해하기 쉬운 설명
    - 기술적 선택의 근거와 대안 고려사항
    - 성능이나 효율성에 대한 분석
    
    **평가 방법:**
    각 기준을 1-5점으로 평가하고, 다음 형식으로 피드백을 제공해주세요:
    
    **[기준별 상세 평가]**
    
    - 점수와 근거
    - 잘된 점
    - 개선이 필요한 점
    
    **[종합 평가]**
    
    - 전체 점수 (가중평균)
    - 문서의 핵심 강점 2-3개
    - 우선 개선사항 3개
    - 개발 과정 문서로서의 완성도 총평
    ```
    
- 결과
    
    ## [기준별 상세 평가]
    
    ### 1. 개발 과정의 완전성 (30%)
    
    **점수: 2/5** → 가중점수: 0.6
    
    **근거:**
    
    - 문제 요구사항이 문서에 길게 복붙되어 있으나, 그에 대한 **자신만의 분석**이나 우선순위, 범위 정의가 부족하다.
    - 설계 단계(모듈 분리, 데이터 흐름, 책임 분배 등)에 대한 구체적 결정 사항, 왜 그렇게 설계했는지에 대한 근거가 거의 없다.
    - 구현은 일부 존재하지만 “왜 이렇게 구현했는지”, “다른 대안은 무엇이었는지”, “어떤 기준으로 선택했는지”가 기록되어 있지 않아 의사결정의 추적이 불가능하다.
    - 시행착오나 변경 내역(예: 초기 설계와 달리 바뀐 점, 실패했던 접근)은 드러나지 않는다.
    
    **잘된 점:**
    
    - 요구사항(기능, 제한 등)을 문서에 빠짐없이 나열해 두었고, 구현 대상이 무엇인지 명확히 하고 있다.
    - 테스트용 함수 분리(`test_*`)처럼 단위별로 접근하려는 시도가 보인다.
    
    **개선 필요점:**
    
    - 문제를 자신의 말로 요약한 분석 섹션을 추가하고, 핵심 제약(예: 비동기, 단일 스레드 모델)과 그것이 설계에 어떤 영향을 준지 기술할 것.
    - 각 모듈(업로드, 변환, 검증, 대시보드 등)의 책임/인터페이스/경계와 선택한 구조에 대한 이유를 기록.
    - 구현 중 발생한 오류, 시도했던 실패한 접근, 그로 인한 수정 과정을 타임스탬프와 함께 남겨야 한다.
    
    ---
    
    ### 2. 과정의 연결성과 맥락 (25%)
    
    **점수: 2/5** → 가중점수: 0.5
    
    **근거:**
    
    - 요구사항 → 설계 → 구현의 흐름이 “연결된 스토리”로 정리되어 있지 않다. 현재는 요구사항이 있고, 코드가 있고, 그 사이를 잇는 설명이 거의 없다.
    - 예를 들어 “업로드가 들어오면 변환으로, 변환 완료면 검증으로” 라는 흐름은 코드로 일부 표현되지만, 왜 이벤트 기반으로 설계했는지, queue를 누가 어떻게 감시하고 분배하는지 등의 맥락 설명이 빠져 있다.
    - 이전 단계 결과가 다음 단계에 어떻게 반영되었는지가 명시적이지 않다. (예: 변환 모듈 확장/병렬 처리 요구가 있을 때 기존 구현을 어떻게 확장할 예정인지가 없음)
    
    **잘된 점:**
    
    - EventEmitter를 중심으로 이벤트 흐름(예: `upload` → `startDecode` → `startLicense`)을 코드로 일부 구성해 놓았다는 점에서 흐름의 개념은 존재.
    - `Dashboard`가 상태를 받아 렌더링하는 구조로 변환/검증 상태를 연결하려는 의도가 보인다.
    
    **개선 필요점:**
    
    - 각 단계 사이의 “무슨 이벤트가, 어떤 조건에서, 누구에게 전달되는지”를 순서도/플로우 차트로 시각화하고 문서화할 것.
    - 모듈 간의 의존성과 데이터 전달 방식(예: upload payload 구조, 상태 전이)을 글로 기술하여 맥락을 명확히 해야 한다.
    - 확장(예: 변환 모듈 여러 개, 검증 모듈 복수) 요구가 있을 때 기존 단일 구조를 어떻게 진화시킬지에 대한 계획을 연결 지어 설명할 것.
    
    ---
    
    ### 3. 코드 실행 결과 기록의 충실성 (25%)
    
    **점수: 2/5** → 가중점수: 0.5
    
    **근거:**
    
    - 코드에 `console.log`가 많지만 **실제 실행 결과(스크린샷/로그 캡처)**가 문서에 포함되어 있지 않다.
    - 테스트 코드가 존재하나, 테스트 수행 결과(통과/실패 여부, 왜 실패했는지, 기대값 vs 실제값 비교 등)는 기록되어 있지 않다.
    - 비동기 타이머를 제어하기 위해 `jest.useFakeTimers()`와 `jest.runAllTimers()`를 쓴 점은 적절하나, 그에 대한 설명(이런 방식으로 비동기 타이밍을 deterministic하게 만드는 이유)이나 테스트 시나리오 설명, 경계 조건 테스트가 없다.
    - 오류 발생 시의 디버깅 과정(예: 예상했던 상태가 안 나왔을 때 어떤 로그를 찍고 어떻게 원인을 좁혔는지)이 없다.
    
    **잘된 점:**
    
    - 테스트용 분리 함수(`test_upload`, `test_startDecode`, ...)를 만들어 “단위 기능”을 독립적으로 실행하려는 설계가 보인다.
    - Jest의 fake timer를 활용해 비동기 시간 흐름을 통제하려는 점은 테스트 환경 설계에서 적절한 기술 선택이다.
    
    **개선 필요점:**
    
    - 각 테스트 케이스에 대해 “무엇을 검증하려는지”, “입력은 무엇이고 기대 출력은 무엇인지”를 명시하고, 실제 실행 로그와 비교해서 문서화할 것.
    - 변환/검증 흐름 관련 정상/비정상 시나리오를 만들고, 그 결과를 기록 (예: 큐에 없을 때, 동시성 충돌, 대기열 처리 순서 등).
    - 실패한 테스트나 예상과 다른 동작이 나왔을 경우 “문제 발견 → 원인 규명 → 해결” 단계를 시계열로 정리할 것.
    
    ---
    
    ### 4. 기술적 설명의 품질 (20%)
    
    **점수: 2/5** → 가중점수: 0.4
    
    **근거:**
    
    - 코드에 주석이 일부 있으나 “왜 이 구조를 썼는가”, “다른 대안은 무엇인가”, “이벤트 기반을 쓴 이유”, “동시성/병렬성을 어떻게 다루려 하는가” 등에 대한 깊이 있는 설명은 거의 없다.
    - 성능이나 확장성(예: 한 번에 하나만 처리하는 변환/검증 모듈에서 다수로 확장할 때 병목이 어디인지, 큐 대기 시간 증가시 어떤 전략을 쓸지)에 대한 언급 없음.
    - 에러 처리/예외 조건에 대한 설명이나 정책이 문서에 없다.
    
    **잘된 점:**
    
    - 모듈 이름과 책임(예: Dashboard, License 검증 등)은 코드로 나뉘어 있고, 그 의도는 부분적으로 드러난다.
    
    **개선 필요점:**
    
    - 핵심 기술 선택(이벤트 에미터 vs 다른 패턴, setTimeout으로 시뮬레이션한 이유, 테스트에서 fake timer 사용 이유)을 문서에 명시하고, 기대 효과와 trade-off를 비교 설명할 것.
    - 각 모듈의 시간 복잡도/병목 가능성을 평가하고, 확장 시 예상되는 문제를 서술할 것.
    - 실패 조건과 복구 전략 (예: 변환 실패시 재시도, 검증 모듈 점유 문제) 을 디자인 문서에 포함할 것.
    
    ---
    
    ## [종합 평가]
    
    - **전체 점수 (가중평균):**
        
        0.6+0.5+0.5+0.4=2.00.6 + 0.5 + 0.5 + 0.4 = 2.00.6+0.5+0.5+0.4=2.0 / 5 → **40점 / 100점** 수준
        
    - **문서의 핵심 강점:**
        1. 요구사항을 빠짐없이 정리해 두어 “무엇을 해야 하는지”는 명확하게 캡쳐되어 있다.
        2. EventEmitter 기반 흐름과 대시보드/모듈 분리를 통해 비동기 파이프라인 구조를 처음부터 염두에 둔 구현 시도가 존재한다.
        3. 테스트를 위해 fake timer를 활용한 구조를 분리해 둔 점은 비동기 환경에서 검증 가능하게 만들려는 의도다.
    - **우선 개선사항 3개:**
        1. **설계 문서 보강:** 분석 → 설계 → 구현으로 이어지는 흐름을 글과 다이어그램(플로우, 책임 분배, 모듈 인터페이스)으로 명확히 기록하라.
        2. **실행 결과 기록:** 테스트 및 실행 로그를 캡처하고, 예상 vs 실제를 비교한 해석을 포함하여 “무슨 일이 언제 일어났는지”를 시계열로 정리하라.
        3. **기술적 이유 설명:** 왜 EventEmitter 구조를 택했는지, 비동기 처리 모델의 장단점, 확장 시 고려사항 등을 명시적으로 기술하여 향후 유지보수자나 자신이 되돌아볼 때 맥락을 제공하라.
    - **개발 과정 문서로서의 완성도 총평:**
        
        현재 문서는 “무엇을 해야 하는지”에 대한 요구사항 수집과 일부 기능 구현 코드가 혼재된 상태로, 개발 과정 문서로서의 일관된 서사나 추적 가능성, 이유 설명이 부족하다. 구조적 기록(설계 결정, 흐름도, 테스트 결과 해석 등)과 맥락 연결이 더해지면 학습용/협업용 문서로서 기본을 갖출 수 있으나, 지금 상태로는 재현성, 판단의 근거, 확장성 검토가 어렵다. 현 수준은 초안 단계이며, 다음 리비전을 통해 “의도 → 선택 → 결과 → 피드백”의 순환이 명확하게 드러나는 구조로 재정비해야 한다.
        
- **설계 문서 보강:** 분석 → 설계 → 구현으로 이어지는 흐름을 글과 다이어그램(플로우, 책임 분배, 모듈 인터페이스)으로 명확히 기록하라.
- **실행 결과 기록:** 테스트 및 실행 로그를 캡처하고, 예상 vs 실제를 비교한 해석을 포함하여 “무슨 일이 언제 일어났는지”를 시계열로 정리하라.
- **기술적 이유 설명:** 왜 EventEmitter 구조를 택했는지, 비동기 처리 모델의 장단점, 확장 시 고려사항 등을 명시적으로 기술하여 향후 유지보수자나 자신이 되돌아볼 때 맥락을 제공하라.
- 후기 및 느낀점
    - 내가 부족하다고 느꼈던 점이다. 단순히 오늘만이 아닌 챌린지 동안 많이 보완하고 싶었던 점인데 이를 정확하게 지적해주니 AI를 통한 채점 피드백도 프롬프트를 잘 작성한다면 정말 도움이 된다고 느꼈다.
    - 이러한 문제점은 문제의 의도를 정확히 파악하지 못하고 학습을 진행하니 문제에 대한 풀이가 엇나가고 학습이 미흡하여 해석이 미흡한 것으로 보인다. 따라서 정확한 문제 파악과 학습 진행에대한 설계를 세우고 이를 바탕으로 체크 포인트를 구체화하여 작성해봐야겠다.
    - +) 다음엔 2.5/5 점은 넘겨보자 .. 😂
