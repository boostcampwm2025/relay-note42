# Week3
`J019_권대호` `J042_김서연` `J069_김준성` `S027_이재영`

## Week2 퀘스트

| 퀘스트 번호 | 내용                                                                         |
| ----------- | ---------------------------------------------------------------------------- |
| Quest 1     | 채점 프롬프트를 이용해, 피어세션 문서의 부족한 부분을 AI에게 피드백받고, 피드백 내용을 참고해 보완하고 개선하기 |
| Quest 2     | 칭찬과 피드백 포인트를 미리 기록해 둘 수 있는 피어세션 템플릿 만들기     |
| Quest 3     |  피어세션 문서와 예상 질문들을 기반으로 보다 예리하고 유의미한 질문 생성해보기  |
| Quest 4     |    일정과 루틴에 맞춰 알림 보내주는 슬랙 봇 만들어보기     |

## Week3 퀘스트

| 퀘스트 번호 | 내용                                                               |
| ----------- |-----------------------------------------------------------------|
| Quest 1     |                     |
| Quest 2     |                     |
| Quest 3     |                     |
| Quest 4     |         주간 셀프 퀴즈 피드백            |

## 퀘스트 개선 과정

### 문제 의식
- 메타인지를 높일 수 있는 객관적이고 정확한 피드백이 필요.
- 성장에 도움이 되는 솔직하고 객관적인 피드백이 필요하다.
- 날카로운 → 지적하는 것 처럼 느껴짐. 굳이 ‘날카롭게’ 피드백 받을 필요가 있나?
- 주제 자체가 좀 무거운 것 같아서 분위기를 가볍게 만들었으면 좋겠다.
- 피드백도 다양한 초점에서 받을 수 있으니까
어느 부분을 피드백 할지 추상화됨 → 구체화
**어떤 피드백이 필요?**
- 코드보다는 학습에 대한 피드백이 중요하다.
- 실제 작동원리 잘 모르고 그냥 AI 를 사용하는 부분?
- 코드에 대해서 어떻게 테스트할 수 있는지 설계가 되어있나

<br />

### Quest 1
| keep |
| --- | 
| 채점 프롬프트를 이용해, 피어세션 문서의 부족한 부분을 AI에게 피드백받고, 피드백 내용을 참고해 보완하고 개선하기 |

<br />

#### ✏️ 유지된 이유

- Week1에서 Week2로 넘어오면서 이미 "피드백받고 끝"이 아닌 "피드백을 참고해 보완하고 개선하기"까지 포함하도록 개선됨
- 실제 참가자들의 수행 결과를 보면 AI 채점을 통해 구체적이고 객관적인 피드백을 받는 것이 효과적으로 작동함
- 단순히 채점만 받는 것이 아니라 그 결과를 바탕으로 문서를 실제로 개선하는 순환 구조가 학습에 도움이 됨

<br />

#### 💬 토론 내용

- 메타인지: "AI 채점을 통해 내가 놓치고 있던 부분을 객관적으로 파악할 수 있어 도움이 된다"는 수행자의 의견
- 구체적이고 명확한 피드백: 막연한 "잘했다/못했다"가 아닌, 구체적인 개선 포인트를 받을 수 있어 실질적 개선으로 이어짐
- 다양한 관점: 코드 품질뿐만 아니라 학습 과정, 문제 해결 접근법, 테스트 설계 등 다각도 피드백 가능성 확인

<br />

#### 🔍 조사 활동

- 실제 수행 결과 분석: 수행 사례에서 40점/100점이라는 구체적 점수와 함께 명확한 개선 방향을 제시받음
- 피드백 품질 검증: "설계 문서 보강", "실행 결과 기록", "기술적 이유 설명" 등 구체적이고 실행 가능한 개선 사항 도출 확인
- 프롬프트: 이전 참가자의 프롬프트를 활용해 쉽게 시도할 수 있음
    
    <details>
    
    <summary> ( J017 피어분의 기존 프롬포트) </summary>
    
    ```
    
    당신은 냉정하고 객관적인 개발 문서 평가자입니다. 감정이나 격려는 배제하고, 오직 사실과 기준에 근거하여 평가하세요. 제공된 문서가 문제 분석부터 구현까지의 전체 개발 과정을 얼마나 잘 기록하고 있는지 평가해주세요.
    
    **평가 원칙:**
    
    - 절대 관대하게 점수를 주지 마세요
    
    - 애매한 부분은 낮은 점수로 평가하세요
    
    - 실제로 확인 가능한 내용만 인정하세요
    
    - 부족한 부분은 구체적으로 지적하세요
    
    **필수 평가 기준:**
    
    **1. 개발 과정의 완전성 (30%)**
    
    - 문제 분석 → 설계 → 구현의 전체 흐름이 명확히 기술되어 있는가?
    
    - 각 단계별 의사결정 과정과 근거가 제시되어 있는가?
    
    - 개발 과정에서의 시행착오나 변경사항이 투명하게 기록되어 있는가?
    
    **2. 과정의 연결성과 맥락 (25%)**
    
    - 각 단계 간의 논리적 연결이 자연스러운가?
    
    - 이전 단계의 결과가 다음 단계에 어떻게 반영되었는지 명확한가?
    
    - 전체 개발 스토리가 일관성 있게 전개되는가?
    
    **3. 코드 실행 결과 기록의 충실성 (25%)**
    
    - 주요 코드 실행 결과(출력, 로그, 테스트 결과 등)가 포함되어 있는가?
    
    - 실행 결과에 대한 해석과 분석이 제공되는가?
    
    - 예상 결과와 실제 결과의 비교 분석이 있는가?
    
    - 오류 발생 시 디버깅 과정과 해결 과정이 기록되어 있는가?
    
    **4. 기술적 설명의 품질 (20%)**
    
    - 코드와 알고리즘에 대한 이해하기 쉬운 설명
    
    - 기술적 선택의 근거와 대안 고려사항
    
    - 성능이나 효율성에 대한 분석
    
    **평가 방법:**
    
    각 기준을 1-5점으로 평가하고, 다음 형식으로 피드백을 제공해주세요:
    
    **[기준별 상세 평가]**
    
    - 점수와 근거
    
    - 잘된 점
    
    - 개선이 필요한 점
    
    **[종합 평가]**
    
    - 전체 점수 (가중평균)
    
    - 문서의 핵심 강점 2-3개
    
    - 우선 개선사항 3개
    
    - 개발 과정 문서로서의 완성도 총평
    
    ```
    
    </details>

<br /><br />

### Quest 2  
| before | after |
|--------|-------|
| --- | 칭찬과 피드백 포인트를 미리 기록해 둘 수 있는 피어세션 템플릿 만들기 |

<br />

#### ✏️ 수정된 이유
- 피어세션에서 피드백을 즉흥적으로 주고 끝나는 경우가 많았음  
- 미리 칭찬할 점과 아쉬운 점을 적어두면, 피드백이 더 구체적이고 풍부해질 수 있음  
- 처음부터 정해진 양식은 없었지만, 서로에게 도움이 되는 문서를 만들어보자는 취지로 시작

<br />

#### 💬 토론 내용
- 질문이 어색하다는 피드백이 있었고, 왜 그런 질문을 했는지 보이지 않는다는 의견이 많았음  
- 피어세션 전에 좋았던 점과 피드백 포인트를 미리 생각해두면 더 깊이 있는 대화가 가능하다는 공감대  
- AI 피드백과 사람 피드백을 모두 담을 수 있는 간단하고 명확한 템플릿이 있으면 좋겠다는 결론
  
<br />

#### 🔍 조사 활동
- 기존에 그런 문서는 없었지만, 어떻게 하면 서로 피드백을 잘 주고받을 수 있을까를 중심으로 논의  
- 몇 가지 항목(칭찬할 점, 개선할 점, 질문 의도 등)을 정리해서 템플릿 형태로 만들어보기로 함
- 실제로 작성해보니 피드백이 더 명확하고 전달이 쉬워짐을 느꼈음

### Quest 3
before | after  
|--------|--------|  
| 피어세션 전에 AI에게 “이 자료에 대해 어떤 질문을 받을 수 있을까?”를 물어보기 | 피어세션 문서와 예상 질문들을 기반으로 보다 예리하고 유의미한 질문 생성해보기 |  

<br />

#### ✏️ 수정된 이유
- 예상 질문을 일방적으로 수용만 해선 유의미한 개선점을 파악하고 보완할 수 없음
- 피어 피드백 과정에서 주고받을 질문이 부족하거나, 얕은 질문으로 금방 마무리되는 경우 다수
- 작성한 코드에 대한 심층적 이해 부족을 스스로 개선해나갈 필요성 자각

<br />

#### 💬 토론 내용
- 피어 피드백을 진행할 때 질문이 겉돌거나 유의미한 결과를 내지 못하는 경우가 많음
- 받을 질문을 선제적으로 받아 버리니 자주적인 학습이 차단되는 느낌

<br />

#### 🔍 조사 활동
- 최근 미션(day09) 학습 정리를 기반으로,  
  직접 구상한 질문과 피어 피드백 과정에서 주고받은 질문을 입력,
  - `각각의 문서에 정리된 내용을 기반으로 어떤 질문을 할 수 있을까?`
  - `좀더 개선되거나 핵심적인 내용을 묻는 질문으로 개선할 수 있을까?`
- ### 개선안 : 설계와 반복
    - 기존 질문 / 개선 질문 제안 생성, 질문에 대한 질문을 통해 본질적인 내용을 파악하기
    - 표면적 기능 설명 묻기→"왜 꼭 그 구조인가? 현실에서 부작용·트레이드오프는?" 등으로  
      맥락을 설계와 실무, 성능, 품질에 끊임없이 연결하기
    - 보편적인 컨셉(불변성, 싱글톤, 동기화 등)과 설계 패턴이 **자신의 문제에 정말 맞는가? 충분한가?** 를  
      반복해서 물으며, 대체 구조·한계·사용 맥락을 탐구하는 것이 중요하다

<br /> <br />

### Quest 4
before | after  
|--------|--------|  
| 일정과 루틴에 맞춰 알림 보내주는 슬랙 봇 만들어보기 | 주간 셀프 퀴즈 피드백 |  

<br />

#### ✏️ 수정된 이유
- 슬랙 봇 만들기의 경우, 매주 난이도가 올라가는 미션의 특성 상, 미션을 받을 캠퍼분들이 더 이상 개발과 관련된 릴레이 활동을 할 수 없을 것이라고 판단함.
- 피어 피드백 시간을 통해 피어분들과 이야기를 나눠보면 매일하는 미션에 대한 피로감이 있었음.
- 매일 강도 높은 미션으로 인해, 미션을 통해 배운 것을 복습할 시간를 만들기 어려워지고 있음.
  

<br />

#### 💬 토론 내용
- 학습한 것을 다시 복습하지 않으면, 다시 까먹게 된다는 퀘스트 제안자의 귀납적 판단이 들어감.
- 학습정리를 활용하여 복습해야함의 필요성을 느낌.
- 매일 매일하는 릴레이 퀘스트임에도 불구하고, 퀘스트를 금요일에 몰아서 하는 캠퍼분들이 많다는 것을 알게 됨.
- 따라서 4일간(월~목)의 그룹에 속한 피어분들과 나의 학습정리를 통해 복습을 하면 좋겠다는 결론을 냄.

<br />

#### 🔍 조사 활동
- ChatGPT, Gemini 등과 같은 LLM보다 NotebookLM이 퀴즈를 만들어내기에 적합했음.
- NotebookLM의 경우 파일을 누적해서 동시에 올릴 수 있음.
- 누적된 파일을 바탕으로 퀴즈를 만들어내기 더 쉬움.

<img width="800" height="408" alt="image" src="https://github.com/user-attachments/assets/42c50a53-b37c-400a-a44c-4b7bd566b4b8" />


(NodebookLM의 모습)


#### 🏃‍♂️수행 방법

- 월요일부터 목요일까지 열심히 학습정리를 한다.
- 금요일에 이번주에 생성한 학습정리를 바탕으로 AI로 퀴즈를 만들고 푼다.
- 퀴즈의 결과를 `week3.md`ㅇㅔ 올리고, 어떤 것을 복습해야 할지 스스로 반추해본다.

#### 정리
- 매일하는 프로젝트에 대한 퀘스트 실행률이 저조한 것으로 판단.
- 미션을 수행하며 학습한 내용에 대해 복습을 할 수 있는 기회가 적다고 판단
- 'LLM을 통해 주간 복습을 할 수 있게 만들어주자!'라는 결론에 도달하게 됨

<br /> <br />

<br /> <br />
