# Week 1 - 릴레이 프로젝트: AI와 함께 더 깊은 피드백을

## 토론한 질문과 주제

저희 42조는 다음과 같은 질문과 아이디어를 중심으로 토론을 진행했습니다.

### 1. 우리가 해결하고 싶은 고민

- 피어세션에서 받는 피드백이 대부분 긍정적인 말에 그쳐, **실질적인 개선점이나 '쓴소리'를 듣기 어렵다**.
- 매일 반복되는 생활 속에서 **성찰과 성장 자극이 부족해지는 문제**가 있다.
- 슬랙의 정보성 콘텐츠나 Q&A 글을 더 잘 정리하고 활용하는 방법은 없을까?
- 질문을 잘 던지는 것도 능력인데, AI가 이를 도와줄 수 있을까?

### 2. 토론 중 나온 아이디어

- 피어세션 문서를 AI가 분석해서 **부족한 부분을 직접 지적해주는 채점 프롬프트** 만들기
- 해당 프롬프트를 매일 조금씩 개선해가며 **더 나은 피드백 도구로 발전시키기**
- AI에게 **질문 자체를 검토받고 다듬기** – 좋은 인풋이 좋은 아웃풋을 만든다!
- 슬랙의 Q&A나 정보 공유 글을 **자동으로 요약하고**, 필요한 맥락을 정리해서 보여주는 봇 만들기
- 나의 루틴을 AI에게 저장시켜 **정해진 시간에 알림 받고 실천 체크하기**

---

## AI를 활용한 사례 조사

### Amazon CodeWhisperer 활용 사례

- 보안 이슈 탐지와 코딩 제안을 동시에 제공 (예: API 키 유출, 민감한 로직 주의 등)
- 실수하기 쉬운 부분에 경고를 주는 피드백
- 일상적인 코딩에서도 책임감 있는 습관 형성에 기여
- 릴레이 노트에서 원하는 방향과 일치하는 점:
  - 성장 과정에서 ‘무의식적 실수’를 AI가 대신 지적
  - 기술뿐 아니라 건강한 개발 습관과 안전한 사고방식을 키우는 데 도움

[참고자료](https://docs.aws.amazon.com/codewhisperer/latest/userguide/whisper-legacy.html)

### Duolingo + GPT-4 활용 사례

- 사람에게 받기 어려운 정직한 피드백
- 지속 가능하고 감정적 부담이 적은 학습 루틴
- 릴레이 노트에서 원하는 방향과 일치하는 점:
  - 감정 소모 없는 소통
  - 습관 형성 유도

[참고자료](https://blog.duolingo.com/duolingo-max/)

---

## 선정된 이번 주 퀘스트

### Quest 1. 피어세션용 문서를 AI로 채점받기

- **배경**: 피어세션에서 실질적인 피드백이 부족했던
- **목표**: 매일 한 개 문서를 AI에게 분석시켜 부족한 점 지적받기
- **수행 기준**: 매일 한 문서 이상 입력하고 피드백 정리하기

### Quest 2. 채점 프롬프트 개선

- **배경**: 초기 프롬프트는 부정확할 수 있으므로 점진적 개선 필요
- **목표**: Quest 1에서 받은 피드백을 바탕으로 프롬프트를 매일 조금씩 수정하기
- **수행 기준**: 매일 수정 전/후 비교해 차이 정리하기 (3일 이상)

### Quest 3. AI에게 더 나은 질문 만들기

- **배경**: 질문을 잘하는 것도 능력이다. 좋은 질문은 더 나은 답변을 만든다.
- **목표**: 내가 만든 질문을 AI가 다듬게 한 후 비교 분석
- **수행 기준**: 매일 1개 이상의 질문 비교 수행 + 개선된 질문과 함께 저장

### Quest 4. 루틴 관리 AI와 함께 하기

- **배경**: 매일 일정 루틴을 지키는 데 어려움이 있음
- **목표**: 자신의 루틴을 AI에게 등록 → 정해진 시간에 알림 받고 이행 여부 체크
- **수행 기준**: 최소 3일간 루틴 저장 → 알림 수신 → 실천 결과 기록

- - -

## 37조의 멤버가 선택한 퀘스트

### `J094 노주호`
1. **`선택한 퀘스트`**
    - `Quest 3. AI에게 더 나은 질문 만들기`
    - **`선택한 이유: 피어원들에게 자주 질문할 기회가 없었는데 AI 에게 질이 좋은 질문을 만들어서 소통을 하고싶습니다.`**
### `J260 지은미`
1. **`선택한 퀘스트`**
    - `Quest 1. 피어세션용 문서를 AI로 채점받기`
    - `Quest 3. AI에게 더 나은 질문 만들기`
    - **`선택한 이유: 내가 정리한 부분의 문서를 분석하여 파악한 부족한 부분피드백 받고, 질문을 통해 개선해나갈 수 있기 때문에 1,3번을 함께 진행한다. 이를 통해 프롬프트를 잘 사용하는 방법을 터득하는 데에도 도움이 될 것 같다.`**
### `J017 곽윤철`
1. **`선택한 퀘스트`**
    - `Quest 1. 피어세션용 문서를 AI로 채점받기`
    - **`선택한 이유: 기존 피어 세션에서는 대부분 긍정적인 피드백에 머물러, 실질적인 개선점이나 '쓴소리'를 듣기 어려웠습니다. AI를 활용해 객관적인 분석으로 명확한 피드백을 받고 싶습니다. 이를 통해 제 문제점을 명확하게 찾고자 합니다.`**
### `S005_김성훈`
1. **`선택한 퀘스트`**
    - `Quest 3. AI에게 더 나은 질문 만들기`
    - **`선택한 이유: 같은 내용을 친절하게 물어봤을 때와 불친절하게 물어봤을 때 답변의 품질이 차이가 나는 경우가 있었고 더 나은 답변을 받기위해 3번 퀘스트를 수행하기로 함`**

## 37조 멤버의 퀘스트 후기

### `J094 노주호`
1. **`선택했던 퀘스트`**
    - `Quest 3. AI에게 더 나은 질문 만들기`
    - `진행 과정:`
        ### 원본 질문
        - 오늘 과제에서 구현했을 때 고려한 게 뭐였나요?

        ### 개선된 질문 버전

        #### 1. 개발 맥락 강조
        > 오늘 과제를 구현할 때 어떤 부분에서 가장 많은 고민이나 결정을 했고, 그 이유는 무엇인가요?

        - **의도:** 단순한 고려사항보다는 **의사결정 과정**과 **우선순위**를 유도

        ---

        #### 2. 기술/구현 중심
        > 오늘 구현한 기능 중에서 기술적으로 가장 신경 쓴 부분은 어디였고, 그걸 선택하게 된 이유는 무엇인가요?

        - **의도:** 사용한 **기술 스택**, **구현 방식의 선택 이유**를 설명하도록 유도

        ---

        #### 3. 사용자 관점 고려
        > 과제를 구현하면서 사용자 경험(UX)이나 효율성 측면에서 특별히 고려한 부분이 있다면 설명해 줄 수 있나요?

        - **의도:** 단순 기능 구현이 아닌 **UX**, **성능 최적화**, **사용자 편의** 요소를 반영했는지 확인

        ### 원본 질문
        - 이 코드를 저렇게 구현하신 이유가 있을까요?

        ### 목적별로 고도화한 질문 12가지

        #### 1. 설계 의도 & 대안 비교
        > 이 설계를 선택한 핵심 이유와, 고려했던 다른 대안(예: A/B 접근) 대비 장단점은 무엇이었나요?

        #### 2. 트레이드오프 명시
        > 성능, 가독성, 유지보수성 사이에서 어떤 트레이드오프를 감수했고, 왜 그렇게 결정했나요?

        #### 3. 복잡도 정당화
        > 현재 구현의 시간/공간 복잡도(O-표기) 관점에서 타당하다고 본 근거는 무엇인가요?

        #### 4. 패턴/아키텍처 선택 근거
        > 사용한 디자인 패턴(예: 전략, 의존성 주입, CQRS 등)이나 아키텍처(레이어드, 헥사고널 등)를 선택한 이유는 무엇인가요?

        #### 5. 데이터 구조 & 알고리즘
        > 선택한 자료구조/알고리즘이 문제 특성(입력 크기, 동시성, 실시간성 등)에 어떻게 최적화되어 있나요?

        #### 6. 에러 처리 & 엣지 케이스
        > 실패/예외/엣지 케이스를 어떻게 식별하고 처리했는지, 그 전략을 선택한 이유는 무엇인가요?

        #### 7. 확장성 & 성능
        > 요청이 10배 증가한다면 현 구현은 어디가 먼저 병목이 되고, 그때 어떤 리팩터링/스케일링 전략을 고려하고 있나요?

        #### 8. 테스트 전략
        > 이 코드의 핵심 리스크를 줄이기 위해 어떤 수준(단위/통합/계약/프로퍼티 기반)으로 테스트를 설계했나요?

        #### 9. 보안 & 프라이버시
        > 입력 검증, 권한, 비밀정보 처리 등 보안 측면에서 특별히 고려한 부분이 있다면 무엇이며, 왜 그렇게 했나요?

        #### 10. 관측 가능성(Observability)
        > 장애가 났을 때 문제를 빨리 좁힐 수 있도록 로깅/메트릭/트레이싱을 어떻게 설계했나요?

        #### 11. 의존성(라이브러리/프레임워크) 선택
        > 외부 라이브러리/프레임워크를 채택(또는 배제)한 기준과 그에 따른 리스크 관리는 어떻게 했나요?

        #### 12. 회고 질문
        > 지금 다시 같은 문제를 푼다면, 어떤 부분을 다르게 구현할 건가요? 그렇게 생각하게 된 근거는 무엇인가요?
    - `후기: 서로 피드백을 하면서 말하기 어려웠던 질문을 AI를 통해 좀 더 구체적이고 유연한 질문으로 바꿔줄 수 있어서 유용하게 이용했던거 같습니다. 다음 피드백에도 충분히 쓸 수 있을만한 질문이었다고 생각합니다.`
### `J260 지은미`
1. **`선택했던 퀘스트`**
    - `Quest 1. 피어세션용 문서를 AI로 채점받기`
    - `Quest 3. AI에게 더 나은 질문 만들기`
    - `진행 과정:`
        ### 릴레이 미션
        - 9일차 과제로 미션을 진행했습니다.

        전체적으로 굉장히 잘 정리되어 있습니다. 아래는 채점 기준에 따른 세부 평가입니다:

        ✅ 채점 기준
        항목	평가 기준	점수 (만점 5점)	피드백
        1. 주제 명확성	Race Condition의 정의와 원인, 대응 방법이 명확히 정리되었는가	5점	개념 정의, 사례, 해결책(Lock, Mutex, 세마포어 등)이 명확히 서술되어 있음
        2. 키워드 반영	IPC, 멀티스레드, 컨텍스트 스위칭 등 핵심 개념이 포함되었는가	5점	IPC 방식(메시지 큐, 공유 메모리), 스케쥴링 및 스레드 구조 모두 잘 설명됨
        3. 미션 요구사항 반영	기능 구현 조건, 예상 동작 예시, 스레드 스케쥴링/타이밍 조정 등의 실습 목적이 서술되었는가	4.5점	대부분 잘 반영되어 있으나, 코드 구현 예시나 실행 구조 시나리오가 있으면 더 좋았음
        4. 사전지식 연결	프로세스/스레드/스케쥴링의 개념이 잘 연결되어 설명되었는가	5점	각 개념이 유기적으로 연결되어 설명되어 이해도가 높음
        5. 비판적 사고/개인화	단순 나열이 아닌, 개인적 이해와 해석, 비교가 드러나는가	5점	JS와 Java 비교, Chrome 브라우저의 구조 등 실사례와 비교가 포함되어 탁월
        6. 시각 자료 활용	도식화, 그림 등의 자료가 학습 효과를 높이는 데 사용되었는가	4.5점	이미지 포함되어 있음. 도식에 대한 간략한 해설이 있으면 더 좋음
        7. 구조화 및 가독성	마크다운의 제목, 표, 리스트 등을 효과적으로 사용했는가	5점	구분이 명확하고 긴 내용임에도 불구하고 흐름이 잘 잡힘

        ##### 🎯 총점: 34 / 35점 (97점)
        등급: A+ (우수)
        본 문서는 학습 주제를 매우 체계적으로 정리하였으며, 핵심 개념의 연계성과 실무적 시사점까지 반영되어 매우 높은 수준입니다.

        ### 개선 제안
        - 🔧 구현 예시 보완: 동작 시나리오나 worker_threads를 이용한 race condition 재현 예시 코드(간단한 예라도)가 포함되면 학습 목적에 완전 부합합니다.
        - 📊 도식 주석 추가: 이미지 아래에 간단한 캡션이나 설명을 붙이면 정리문서로서 완성도가 올라갑니다.

        ---
        #### 개선하기
        > 좀 개선해야할 부분이 있을까? 내가 진행해봤을 때 worker thread 사용법은 이해가 가는데 내부 동작 원리는 아직 좀 부족한거 같아서

        ```
        🔍 개선 포인트 요약
        ## 🧠 Worker Thread의 내부 동작 원리

        Node.js는 기본적으로 싱글 스레드 이벤트 루프 기반으로 동작하지만, `worker_threads` 모듈을 통해 멀티스레드를 명시적으로 사용할 수 있다. 이때 생성되는 `Worker`는 단순한 스레드가 아닌, **독립적인 실행 컨텍스트와 이벤트 루프**를 가지는 고급 구조다.

        ---

        ### ✅ Worker Thread 구조

        - **독립된 V8 컨텍스트**  
        Worker는 메인 스레드와 별도의 V8 실행 컨텍스트를 갖는다. 즉, 각 Worker는 자체 스코프/환경에서 실행된다.  

        - **독립된 libuv 이벤트 루프**  
        메인 스레드의 이벤트 루프와는 별개의 이벤트 루프를 가지고 있어, 동시에 여러 작업을 비동기적으로 처리할 수 있다.


        Main Thread
        ├─ Event Loop (libuv)
        ├─ V8 Context
        └─ Worker Thread 생성 → 내부적으로 새로운 OS-level Thread 생성

        Worker Thread
        ├─ 별도의 Event Loop
        ├─ 독립된 V8 Context
        └─ 독립 실행


        📬 메시지 전달 구조

        Worker와 메인 스레드는 postMessage()와 on('message')를 통해 통신하며, 내부적으로는 다음과 같은 구조로 동작한다.

        메시지 복사 vs 공유
        (중간 생략)

        📌 요약
        - Worker Thread는 메인 이벤트 루프와 완전히 분리된 독립적인 실행 환경이다.
        - postMessage()는 비동기 메시지 기반이며, 공유 메모리는 SharedArrayBuffer로 사용 가능하다.
        - 공유 메모리는 빠르지만 정합성 유지를 위해 반드시 Atomics API와 함께 사용해야 한다.
        - I/O는 libuv, CPU 연산은 Worker Thread로 분리하는 것이 이상적이다.
        ```

        ### 결과 
        다음과 같은 형식으로 내가 부족한 했던 개념 부분에 대해 요청을 부탁했고, 추가적으로 내가 정리하지 못한 부분들을 개선하여 정리본을 만들어주었다 !
    - `후기: 생각보다 내가 정리하면서 제대로 정리했나? 라는 고민이 들었던 적이 많은데, AI로 내 정리본에 채점 결과를 수치화하여 분석 결과도 알려주는 부분이 좋았던 것 같다. 아직 조금 더 개선하여 정리하는 부분에서는 질문의 퀄리티나 정리하는 방식을 조금 더 학습시켜 실험해봐야겠다는 생각을 했다. 아쉬웠던건 지피티 특유의 정리 방식으로 정리를 진행해줘서 내가 정리한 느낌이 안난다는 아쉬움이 있었다. 내가 정리하는 방식에 대해 학습을 시켜놓은 뒤, 정리를 부탁하면 더 만족하는 정리본을 얻을 수 있을 것 같다.`
### `J017 곽윤철`
1. **`선택했던 퀘스트`**
    - `Quest 1. 피어세션용 문서를 AI로 채점받기`
    - `진행 과정:`
        ### QUEST1: 피어세션용 README 문서 평가

        기존 피어 세션에서는 동료 캠퍼들과의 관계를 고려하다 보니 "좋은데요", "잘 구현하신 것 같아요" 같은 표면적 피드백이 주를 이뤘다. 이는 다음과 같은 문제를 야기했다:

        - 구체적 개선점 부재: 무엇을 어떻게 고쳐야 하는지 모호함
        - 피드백 회피: 비판적 의견을 제시하기 어려운 분위기
        - 성장 정체: 실질적인 발전 방향을 찾기 어려움

        AI는 관계적 부담 없이 객관적 평가가 가능하다는 점에서 근본적으로 다른 접근을 제공한다:

        - 무자비한 정확성: 감정적 배려 없이 사실에 기반한 평가
        - 체계적 분석: 일관된 기준으로 다각도 검토
        - 구체적 지적: 추상적 격려가 아닌 명확한 개선 방향 제시

        ### AI 피드백을 통해 발견한 문제점

        [사용한 문서: Day08](https://gist.github.com/YunDo-Gi/2400b07ea8479cce9e8e66709b2d00a3)

        <details>
        <summary>사용 프롬프트</summary>

        ```markdown
        당신은 냉정하고 객관적인 개발 문서 평가자입니다. 감정이나 격려는 배제하고, 오직 사실과 기준에 근거하여 평가하세요. 제공된 문서가 문제 분석부터 구현까지의 전체 개발 과정을 얼마나 잘 기록하고 있는지 평가해주세요.

        **평가 원칙:**

        - 절대 관대하게 점수를 주지 마세요
        - 애매한 부분은 낮은 점수로 평가하세요
        - 실제로 확인 가능한 내용만 인정하세요
        - 부족한 부분은 구체적으로 지적하세요

        **필수 평가 기준:**

        **1. 개발 과정의 완전성 (30%)**

        - 문제 분석 → 설계 → 구현의 전체 흐름이 명확히 기술되어 있는가?
        - 각 단계별 의사결정 과정과 근거가 제시되어 있는가?
        - 개발 과정에서의 시행착오나 변경사항이 투명하게 기록되어 있는가?

        **2. 과정의 연결성과 맥락 (25%)**

        - 각 단계 간의 논리적 연결이 자연스러운가?
        - 이전 단계의 결과가 다음 단계에 어떻게 반영되었는지 명확한가?
        - 전체 개발 스토리가 일관성 있게 전개되는가?

        **3. 코드 실행 결과 기록의 충실성 (25%)**

        - 주요 코드 실행 결과(출력, 로그, 테스트 결과 등)가 포함되어 있는가?
        - 실행 결과에 대한 해석과 분석이 제공되는가?
        - 예상 결과와 실제 결과의 비교 분석이 있는가?
        - 오류 발생 시 디버깅 과정과 해결 과정이 기록되어 있는가?

        **4. 기술적 설명의 품질 (20%)**

        - 코드와 알고리즘에 대한 이해하기 쉬운 설명
        - 기술적 선택의 근거와 대안 고려사항
        - 성능이나 효율성에 대한 분석

        **평가 방법:**
        각 기준을 1-5점으로 평가하고, 다음 형식으로 피드백을 제공해주세요:

        **[기준별 상세 평가]**

        - 점수와 근거
        - 잘된 점
        - 개선이 필요한 점

        **[종합 평가]**

        - 전체 점수 (가중평균)
        - 문서의 핵심 강점 2-3개
        - 우선 개선사항 3개
        - 개발 과정 문서로서의 완성도 총평
        ```

        </details>

        <details>
        <summary>결과</summary>

        ```markdown
        ## 개발 문서 평가 보고서

        ### [기준별 상세 평가]

        **1. 개발 과정의 완전성 (30%) - 점수: 3/5**

        **근거:**

        - 문제 분석 → 설계 → 구현의 기본 흐름은 존재하나 불완전
        - 설계 단계에서 "어떤 연결리스트를 사용할까?" 등의 의사결정 과정이 일부 기록됨
        - 해시맵에서 체이닝 방식 선택 근거 제시

        **잘된 점:**

        - 단일 연결리스트 선택 근거가 해시맵 활용 목적과 연계되어 설명됨
        - 함수형 프로그래밍 제약 조건 하에서의 해결 방안 모색 과정 기록

        **개선 필요점:**

        - 초기 요구사항 분석이나 문제 정의 부분 누락
        - 각 기능별 상세 설계 과정이 생략됨
        - 시행착오나 리팩토링 과정이 단편적으로만 언급됨 (해시 함수 구현 변경 등)

        **2. 과정의 연결성과 맥락 (25%) - 점수: 2/5**

        **근거:**

        - 연결리스트 → 해시맵 → 라이브러리 순서는 논리적이나 연결 설명 부족
        - 각 모듈 간의 의존성이나 활용 관계가 명시적으로 설명되지 않음

        **잘된 점:**

        - 연결리스트를 해시맵에서 체이닝 용도로 활용한다는 전체 구조 언급
        - 함수형 프로그래밍 원칙이 전체 구현에 일관되게 적용

        **개선 필요점:**

        - 왜 이 순서로 개발했는지에 대한 설명 부족
        - 이전 단계 결과물이 다음 단계에서 어떻게 구체적으로 활용되는지 불명확
        - 전체 아키텍처 관점에서의 설계 흐름 부재

        **3. 코드 실행 결과 기록의 충실성 (25%) - 점수: 4/5**

        **근거:**

        - 스크린샷으로 테스트 실행 결과 제공
        - 동작 확인 코드와 출력 결과 모두 기록
        - 각 기능별로 실제 동작하는 예제 포함

        **잘된 점:**

        - 연결리스트, 해시맵, 라이브러리 모든 모듈의 테스트 결과 스크린샷 제공
        - 라이브러리 기능 동작 확인을 위한 실제 코드 실행 과정 상세 기록
        - Jest 테스트 결과를 통한 검증 과정 명시

        **개선 필요점:**

        - 스크린샷만으로는 구체적인 출력값 확인이 어려움
        - 에러 케이스나 예외 상황 테스트 결과 부족
        - 성능 테스트나 대용량 데이터 처리 결과 없음

        **4. 기술적 설명의 품질 (20%) - 점수: 3/5**

        **근거:**

        - 핵심 알고리즘과 자료구조에 대한 기본적인 설명 포함
        - 코드 주석과 함께 구현 의도 설명
        - 일부 기술적 선택에 대한 근거 제시

        **잘된 점:**

        - Polynomial Rolling Hash 알고리즘 설명과 공식 제시
        - 재귀를 활용한 탐색 방식의 구현 배경 설명
        - 불변성 유지를 위한 구체적인 코드 패턴 제시

        **개선 필요점:**

        - 시간/공간 복잡도 분석 부재
        - 대안 기술들과의 비교 분석 부족
        - 확장성이나 유지보수성 관점의 설계 고려사항 미흡

        ### [종합 평가]

        **전체 점수: 2.9/5 (가중평균)**

        - 개발 과정의 완전성: 3 × 0.3 = 0.9
        - 과정의 연결성과 맥락: 2 × 0.25 = 0.5
        - 코드 실행 결과 기록: 4 × 0.25 = 1.0
        - 기술적 설명의 품질: 3 × 0.2 = 0.6

        **문서의 핵심 강점:**

        1. **실행 검증의 완전성**: 모든 구현물에 대한 테스트 결과를 스크린샷과 코드로 상세히 기록
        2. **함수형 프로그래밍 일관성**: 불변성, 순수함수 등 함수형 원칙을 전체 구현에 일관되게 적용
        3. **실용적 구현 접근**: 추상적 이론보다는 실제 동작하는 코드와 결과에 중점

        **우선 개선사항:**

        1. **개발 과정 맥락화**: 각 단계별 의사결정 과정과 단계 간 연결고리를 명확히 기술
        2. **초기 분석 단계 보강**: 요구사항 분석, 문제 정의, 전체 아키텍처 설계 과정 추가
        3. **기술적 분석 심화**: 성능 분석, 복잡도 계산, 대안 기술 비교 등 깊이 있는 기술 검토

        **개발 과정 문서로서의 완성도 총평:**
        이 문서는 구현 결과물의 동작 검증에는 충실하나, 개발자의 사고 과정과 의사결정 여정을 추적하기에는 부족하다. 코드 중심의 기록에서 벗어나 '왜', '어떻게'의 과정을 더 상세히 기록할 필요가 있다. 특히 전체 시스템의 맥락에서 각 모듈의 역할과 연계성을 설명하는 부분이 현저히 부족하여, 독자가 전체적인 개발 스토리를 이해하기 어려운 구조이다.
        ```

        </details>

        #### 1. 개발 과정 기록의 표면성

        발견된 문제:

        ```
        "연결리스트를 해시맵에 활용한다"는 언급은 있지만,
        왜 이 순서로 개발했는지, 각 단계에서 어떤 고민을 했는지가 누락됨
        ```

        기술 문서를 작성할 때 결과물 중심 사고에 갇혀 있었다. "무엇을 만들었는가"에만 집중하고 "왜 이렇게 접근했는가"라는 사고 과정을 기록하지 않았다.

        #### 2. 맥락 없는 모듈 간 연결

        발견된 문제:

        ```
        연결리스트 → 해시맵 → 라이브러리 순서는 논리적이나
        각 모듈 간의 의존성이나 활용 관계가 명시적으로 설명되지 않음
        ```

        개별 기능 구현에는 집중했지만 전체 아키텍처 관점이 부족했다. 각 모듈을 독립적으로 바라보며, 전체 시스템에서의 역할과 상호작용을 설명하지 못했다.

        #### 3. 기술적 깊이의 한계

        발견된 문제:

        ```
        시간/공간 복잡도 분석 부재
        대안 기술들과의 비교 분석 부족
        ```

        "일단 돌아가게 만들자"는 사고에서 벗어나지 못했다. 엔지니어링 관점에서의 성능, 효율성, 확장성 고려가 부족했다. 단순히 요구사항을 만족하는 것을 넘어서 최적화와 대안 검토까지 포함하는 깊이 있는 접근이 필요함을 깨달았다.

        ### AI 피드백의 예상치 못한 통찰들

        #### 1. 수치화된 객관성의 충격

        `점수 2.9/5`라는 구체적 수치를 받았을 때의 충격이 컸다. 막연히 "괜찮게 했다"고 생각했던 것이 객관적 기준으로는 평균 이하였다는 현실을 직면했다.

        #### 2. 가중치를 통한 우선순위 명확화

        개발 과정의 완전성 (30%) - 3점
        과정의 연결성과 맥락 (25%) - 2점 ← 가장 취약
        단순히 "부족하다"가 아니라 어느 영역이 얼마나 중요하고 얼마나 부족한지 명확한 우선순위를 얻었다.

    - `후기: 10분 투자로 객관적 시각을 얻을 수 있어서 괜찮은 퀘스트인 것 같다. AI 점수에 집착하지 않고 참고용으로만 활용하면서 계속 진행할 예정이다.`
### `S005_김성훈`
1. **`선택했던 퀘스트`**
    - `Quest 3. AI에게 더 나은 질문 만들기`
    - `진행 과정`
        ### **✅ 오늘 저녁 뭐먹을까?**

        **원본 질문**:

        > 오늘 저녁 뭐먹을까?

        **개선된 질문**:

        > 오늘 좀 지쳐서 기운이 나는 따뜻한 저녁이 먹고 싶어. 집에서 간단히 만들거나 배달로 시킬 수 있는 메뉴 추천해줄 수 있어?

        **비교 포인트**:

        - 감정/컨디션 추가 (지침 -> 회복 필요)
        - 상황 명시 (요리 or 배달)
        - 구체적 기대치 반영 (따뜻함, 간단함)

        ---

        ### **✅ 집중력이 떨어지는데 좋은 방법 없을까?**

        **원본 질문**:

        > 집중력이 떨어지는데 좋은 방법 없을까?

        **개선된 질문**:

        > 요즘 집중력이 30분도 안 가서 고민이야. 실내에서 쉽게 실천할 수 있고, 디지털 기기에 의존하지 않는 집중력 향상 방법이 있을까?

        **비교 포인트**:

        - 문제의 구체성 강화 (30분 이하 지속)
        - 제약 조건 명시 (실내, 비디지털)
        - 현실적인 기대 설정

        ---

        ### **✅ 영어 공부 어떻게 해야 돼?**

        **원본 질문**:

        > 영어 공부 어떻게 해야 돼?

        **개선된 질문**:

        > 영어 말하기 실력을 늘리고 싶은데, 하루 30분 정도 투자할 수 있을 때 실생활에 바로 쓸 수 있는 공부법이 있을까?

        **비교 포인트**:

        - 목표 구체화 (말하기)
        - 시간 자원 명시 (30분)
        - 실용성 강조 (실생활 활용)

        ---

        ### **✅ 왜 보드게임에서 타노스2 vs 어벤져스8로 생각했나요?**

        **원본 질문**:

        > 왜 보드게임에서 타노스2 vs 어벤져스8로 생각했나요?

        **개선된 질문**:

        > 보드게임 설계 시 타노스 2명 vs 어벤져스 8명이라는 구조를 선택한 이유가 궁금해요. 밸런스나 역할 분배, 플레이어 경험 측면에서 어떤 점을 고려했나요?

        **비교 포인트**:

        - 의도 명확화 (단순 의문 -> 설계 이유 탐색)
        - 맥락 강조 (밸런스, 역할, UX)
        - 개발자 관점 반영

        ### **✅ 단위 테스트를 작성할 때 고려한 게 뭔가요?**

        **원본 질문**:

        > 단위 테스트를 작성할 때 고려한 게 뭔가요?

        **개선된 질문**:

        > 이 미션에서 단위 테스트를 작성할 때, 어떤 기준으로 테스트 대상을 정했고 어떤 경우의 수를 우선순위에 두었는지 궁금합니다.

        **비교 포인트**:

        - 구체적 맥락 추가 (이 미션)
        - 단순 “고려” -> 판단 기준과 전략
        - 테스트 설계 의도 파악 중심

        ---

        ### **✅ 함수형 프로그래밍이 읽기 좋았나요, 객체지향 프로그래밍이 읽기 좋았나요?**

        **원본 질문**:

        > 함수형 프로그래밍이 읽기 좋았나요, 객체지향 프로그래밍이 읽기 좋았나요?

        **개선된 질문**:

        > 이 프로젝트에서는 함수형 방식과 객체지향 방식 중 어떤 쪽이 더 읽기 쉬웠나요? 그 이유는 코드 흐름, 상태 관리, 협업 측면 중 어떤 부분이 영향을 미쳤는지도 궁금합니다.

        **비교 포인트**:

        - 단순 비교 -> 이유/맥락 유도
        - 읽기 쉬움의 기준 명확화 (흐름, 상태, 협업)
        - 적용된 사례에 연결

        ---

        ### **✅ 설계할 때 고려한 게 뭔가요?**

        **원본 질문**:

        > 설계할 때 고려한 게 뭔가요?

        **개선된 질문**:

        > 이 구조를 설계할 때 가장 먼저 고려한 우선순위가 궁금합니다. 성능, 유지보수성, 확장성 중 어떤 요소에 중점을 두었고 그 이유는 무엇인가요?

        **비교 포인트**:

        - 막연한 질문 -> 설계 요소 명시
        - 우선순위 중심의 유도
        - 비교 기준 제공으로 답변 유도
    - `후기: 막연했던 질문을 AI를 통해 감정, 맥락, 목적, 제약 조건 등을 고려하게 개선했더니 답변의 길이와 실용성이 확실하게 달라졌습니다. 단순한 궁금증이 설계 의도나 전략적인 관점으로 확장되었고 대화가 풍부해져서 좋았습니다. 앞으로는 "무엇을 알고 싶은지"뿐만 아니라 "왜, 어떤 상황에서" 궁금한지도 함께 담는 것이 중요하다는 것을 체감했습니다.`
